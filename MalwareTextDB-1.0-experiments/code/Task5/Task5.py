"""
------------------------------------------------------------
Task5.py
------------------------------------------------------------

Predict attribute labels for the different attribute
categories.

Run using
    python Task5.py <run>
where <run> is an experiment run number ie. an integer from
1 to 5 inclusive.
------------------------------------------------------------
"""

from __future__ import print_function
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.svm import LinearSVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.multiclass import OneVsRestClassifier
from sklearn import metrics

import numpy as np
import sys
from os import listdir

def main():

    # if len(sys.argv)==2:
    #     try:
    #         run = int(sys.argv[1])
    #         if run>5 or run<1:
    #             print("Enter experiment run number (1 to 5).")
    #             return
    #     except ValueError:
    #         print("Enter experiment run number.")
    #         return
    # else:
    #     print("Enter experiment run number.")
    #     return

    tokenFolder = "../../data/tokenized/"
    annFolder = "../../data/annotations/"

    documents = []

    # Retrieve list of signatures
    # signaturesMasterList contains vectors A
    # where A[0] is the document name and A[1] is the list of signatures for that document
    # signatures contains the total list of signature types
    signaturesMasterList,signatures = getSignatures()

    documents = []
    texts = []
    attributes = []

    # Get texts
    # This retrieves all the tokens for each document
    for entry in signaturesMasterList:
        document = entry[0].split('/')[-1].split('.')[0]+'.tokens'
        for fileName in listdir(tokenFolder):
            if fileName==document:
                texts.append(getText(tokenFolder+fileName))

    # Get attributes
    # This retrieves all the attribute labels for each document
    for entry in signaturesMasterList:
        document = entry[0].split('/')[-1].split('.')[0]+'.ann'
        documents.append(document)
        for fileName in listdir(annFolder):
            if fileName==document:
                attributes.append(getAttributes(annFolder+fileName))

    # Assign data
    results = {'svm':{'txt':[], 'att':[], 'both':[]}, 'nb':{'txt':[], 'att':[], 'both':[]}}
    print('         {:^22s} |    {:^22s}'.format('SVM', 'Naive Bayes'))
    print('         {:^5s} {:^5s} {:^5s} {:^4s} |    {:^5s} {:^5s} {:^5s} {:^4s}'.format('P', 'R', 'F', 'n', 'P', 'R', 'F', 'n'))
    for run in range(1,6):
        trainingSet,devSet,testSet,SVC_para,NB_para = getRunData(run)

        trainX_txt,trainX_att,trainY = assignData(trainingSet,texts,attributes,signaturesMasterList)
        devX_txt,devX_att,devY = assignData(devSet,texts,attributes,signaturesMasterList)
        testX_txt,testX_att,testY = assignData(testSet,texts,attributes,signaturesMasterList)

        allX_txt = trainX_txt+devX_txt+testX_txt

        # Use MultiLabelBinarizer to convert the lists of signatures
        # Need to include pre-defined list of all signatures
        mlb = MultiLabelBinarizer(classes=signatures)
        trainY = mlb.fit_transform(trainY)
        devY = mlb.fit_transform(devY)
        testY = mlb.fit_transform(testY)

        regRange = range(-3,4)
        #"""
        # print "SVC - txt"
        results['svm']['txt'].append(testModel("SVC",regRange,1,0,allX_txt,trainX_txt,devX_txt,testX_txt,trainX_att,devX_att,testX_att,trainY,devY,testY,signatures))
        # print "NB - txt"
        results['nb']['txt'].append(testModel("NB",regRange,1,0,allX_txt,trainX_txt,devX_txt,testX_txt,trainX_att,devX_att,testX_att,trainY,devY,testY,signatures))
        # print "SVC - att"
        results['svm']['att'].append(testModel("SVC",regRange,0,1,allX_txt,trainX_txt,devX_txt,testX_txt,trainX_att,devX_att,testX_att,trainY,devY,testY,signatures))
        # print "NB - att"
        results['nb']['att'].append(testModel("NB",regRange,0,1,allX_txt,trainX_txt,devX_txt,testX_txt,trainX_att,devX_att,testX_att,trainY,devY,testY,signatures))
        # print "SVC - both"
        results['svm']['both'].append(testModel("SVC",regRange,1,1,allX_txt,trainX_txt,devX_txt,testX_txt,trainX_att,devX_att,testX_att,trainY,devY,testY,signatures))
        # print "NB - both"
        results['nb']['both'].append(testModel("NB",regRange,1,1,allX_txt,trainX_txt,devX_txt,testX_txt,trainX_att,devX_att,testX_att,trainY,devY,testY,signatures))
        #"""
        print('Experiment {}'.format(run))
        for att in ['txt', 'att', 'both']:
            print('{2:4s}: {3:2d} {0[0]:5.2f} {0[1]:5.2f} {0[2]:5.2f} {0[4]:4d} | {4:2d} {1[0]:5.2f} {1[1]:5.2f} {1[2]:5.2f} {1[4]:4d}'.format(results['svm'][att][-1]['scores'], results['nb'][att][-1]['scores'], att, results['svm'][att][-1]['alpha'], results['nb'][att][-1]['alpha']))
    overall = {}
    for model in ['svm', 'nb']:
        overall[model] = {}
        for att in ['txt', 'att', 'both']:
            overall[model][att] = [0, 0, 0, 0, 0, 0]
    micro_average = True
    for att in ['txt', 'att', 'both']:
        for model in ['svm', 'nb']:
            for result in results[model][att]:
                for i in range(6):
                    overall[model][att][i] += result['scores'][i]
    for att in ['txt', 'att', 'both']:
        for model in ['svm', 'nb']:
            if micro_average:
                overall[model][att][0] = 100.0*overall[model][att][5]/overall[model][att][3]
                overall[model][att][1] = 100.0*overall[model][att][5]/overall[model][att][4]
                overall[model][att][2] = harm_mean(overall[model][att][0], overall[model][att][1])
            else:
                for i in range(3):
                    overall[model][att][i] /= 5
    print('Overall Results')
    print('{:4s} {:^22s} | {:^22s}'.format('', 'SVM', 'Naive Bayes'))
    print('{:4s} {:^5s} {:^5s} {:^5s} {:^4s} | {:^5s} {:^5s} {:^5s} {:^4s}'.format('', 'P', 'R', 'F', 'n', 'P', 'R', 'F', 'n'))
    for att in ['txt', 'att', 'both']:
        print('{2:4s} {0[0]:5.2f} {0[1]:5.2f} {0[2]:5.2f} {0[4]:4d} | {1[0]:5.2f} {1[1]:5.2f} {1[2]:5.2f} {1[4]:4d}'.format(overall['svm'][att], overall['nb'][att], att))
    print()

def harm_mean(a, b):
    if a*b == 0.0:
        return 0.0
    else:
        return 2*a*b/(a+b)

def testModel(modelType,regVal,scale_txt,scale_att,allX_txt,trainX_txt,devX_txt,testX_txt,trainX_att,devX_att,testX_att,trainY,devY,testY,signatures):

    f1 = []

    cv = CountVectorizer(ngram_range=(1,2))

    allX_txt = cv.fit_transform(allX_txt)

    # cv = CountVectorizer(ngram_range=(1,2),vocabulary=cv.vocabulary_)

    trainX_txt = cv.transform(trainX_txt).toarray()
    devX_txt = cv.transform(devX_txt).toarray()
    testX_txt = cv.transform(testX_txt).toarray()

    if scale_txt==0:
        trainX_both = trainX_att
        devX_both = devX_att
        testX_both = testX_att
    elif scale_att==0:
        trainX_both = trainX_txt
        devX_both = devX_txt
        testX_both = testX_txt
    else:
        trainX_both = np.append(scale_txt*trainX_txt,scale_att*trainX_att,axis=1)
        devX_both = np.append(scale_txt*devX_txt,scale_att*devX_att,axis=1)
        testX_both = np.append(scale_txt*testX_txt,scale_att*testX_att,axis=1)

    for i,reg in enumerate(regVal):

        if modelType=="SVC":
            model = OneVsRestClassifier(LinearSVC(C=10**reg))
        elif modelType=="NB":
            model = OneVsRestClassifier(MultinomialNB(alpha=10**reg))

        model.fit(trainX_both,trainY)

        expected = devY
        predicted = model.predict(devX_both)

        f1.append([metrics.f1_score(expected,predicted,average='micro'),i])

    f1.sort()

    if model=="SVC":
        model = OneVsRestClassifier(LinearSVC(C=10**regVal[f1[-1][1]]))
    elif model=="NB":
        model = OneVsRestClassifier(MultinomialNB(alpha=10**regVal[f1[-1][1]]))

    model.fit(trainX_both,trainY)

    expected = testY
    predicted = model.predict(testX_both)

    # print metrics.classification_report(expected, predicted, digits=4, target_names=signatures)
    p,r,f,s =    metrics.precision_recall_fscore_support(expected, predicted,average='micro')
    gold = sum(metrics.precision_recall_fscore_support(expected, predicted)[3])
    correct = int(round(gold*r))
    predicted = int(round(correct/p))
    # print str(p)+'\t'+str(r)+'\t'+str(f)
    # print regVal[f1[-1][1]]
    return {'alpha':regVal[f1[-1][1]], 'scores':(100*p, 100*r, 100*f, predicted, gold, correct)}


def getSignatures():

    signaturesFile = "signatures.list"

    signaturesMasterList = []
    signaturesSublist = []
    i = -1
    document = ''

    with open(signaturesFile,'r') as f:
        for line in f:
            if line[:3]=="In ":
                if len(document)>0:
                    signaturesMasterList.append([document])
                    signaturesMasterList[-1].append(signaturesSublist)
                document = line.split(': ')[-1][:-1]
                signaturesSublist = []
            elif line[:4]=="Sign":
                signatures = line[5:-1].split('\t')
                for signature in signatures:
                    if len(signature)>1:
                        if signature not in signaturesSublist: signaturesSublist.append(signature)
        # Add last document
        if len(document)>0:
            signaturesMasterList.append([document])
            signaturesMasterList[-1].append(signaturesSublist)
    #"""
    # remove signature types that occur <5 times

    signatureTypes = []
    signatureCounts = []
    toRemove = []
    for signaturesSublistNo,signaturesSublist in enumerate(signaturesMasterList):
        for signature in signaturesSublist[1]:
            if signature not in signatureTypes:
                signatureTypes.append(signature)
                signatureCounts.append([1,signature])
            else:
                signatureCounts[signatureTypes.index(signature)][0]+=1

    for signatureCount in signatureCounts:
        if signatureCount[0]<10: toRemove.append(signatureCount[1])

    for signaturesSublistNo,signaturesSublist in enumerate(signaturesMasterList):
        for signature in reversed(signaturesSublist[1]):
            if signature in toRemove:
                signaturesMasterList[signaturesSublistNo][1].pop(signaturesMasterList[signaturesSublistNo][1].index(signature))

    #"""
    # remove documents with 0 signatures
    signatureTypes = []
    signatureCounts = []
    toRemove = []
    for signaturesSublistNo,signaturesSublist in enumerate(signaturesMasterList):
        if len(signaturesSublist[1])<1: toRemove.append(signaturesSublistNo)
        for signature in signaturesSublist[1]:
            if signature not in signatureTypes:
                signatureTypes.append(signature)
                signatureCounts.append([1,signature])
            else:
                signatureCounts[signatureTypes.index(signature)][0]+=1
    signatureCounts.sort()
    #for signature in signatureCounts:
        #print signature[1]+'\t'+str(signature[0])
    for index in reversed(toRemove):
        signaturesMasterList.pop(index)

    #for signaturesSublistNo,signaturesSublist in enumerate(signaturesMasterList):
        #print signaturesSublist[0]+'\t'+str(len(signaturesSublist[1]))

    # generate signature index
    signatureIndex = []
    for signaturesSublist in signaturesMasterList:
        for signature in signaturesSublist[1]:
            if signature not in signatureIndex: signatureIndex.append(signature)

    signatureIndex.sort()

    return signaturesMasterList,signatureIndex

def getText(fileName):

    text = ''

    with open(fileName,'r') as f:
        for line in f:
            if line!='\n': text+=line.split(' ')[0]

    return text

def getAttributes(fileName):

    attVector = []
    for i in range(444):
        attVector.append(0)

    with open(fileName,'r') as f:
        for line in f:
            if line[0]=='A':
                attributeIndex = int(line[:-1].split('\t')[1].split(' ')[-1].split(':')[0])
                attributeType = line[:-1].split('\t')[1].split(' ')[0]
                if attributeType=="Capability": attributeIndex+=211
                elif attributeType=="StrategicObjectives": attributeIndex+=231
                elif attributeType=="TacticalObjectives": attributeIndex+=296
                attVector[attributeIndex] = 1

    return attVector

def getRunData(run):

    datasets = {}

    trainingSet1 = [29, 2, 11, 15, 19, 9, 28, 5, 10, 0, 25, 12, 3, 26, 6, 17, 4, 13]
    devSet1 = [30, 22, 27, 21, 16, 7]
    testSet1 = [14, 18, 1, 8, 23, 20, 24]
    SVC_para_1 = -1
    NB_para_1 = -1

    trainingSet2 = [19, 1, 0, 5, 11, 14, 25, 27, 29, 21, 18, 16, 20, 9, 28, 10, 8, 4]
    devSet2 = [22, 30, 2, 13, 3, 15]
    testSet2 = [7, 6, 26, 24, 17, 23, 12]
    SVC_para_2 = -1
    NB_para_2 = -1

    trainingSet3 = [27, 15, 24, 9, 5, 29, 18, 2, 17, 19, 23, 0, 26, 20, 8, 12, 11, 16]
    devSet3 = [4, 28, 1, 25, 3, 7]
    testSet3 = [22, 6, 30, 10, 14, 21, 13]
    SVC_para_3 = -1
    NB_para_3 = -1

    trainingSet4 = [15, 8, 24, 6, 11, 0, 12, 27, 10, 19, 30, 29, 18, 4, 23, 2, 22, 1]
    devSet4 = [13, 26, 14, 5, 7, 28]
    testSet4 = [9, 25, 17, 3, 16, 21, 20]
    SVC_para_4 = -1
    NB_para_4 = -1

    trainingSet5 = [17, 4, 13, 16, 20, 28, 0, 15, 1, 27, 21, 23, 10, 14, 2, 12, 8, 9]
    devSet5 = [24, 7, 19, 5, 3, 26]
    testSet5 = [6, 11, 29, 18, 25, 22, 30]
    SVC_para_5 = -1
    NB_para_5 = -1

    datasets[1] = (trainingSet1,devSet1,testSet1,SVC_para_1,NB_para_1)
    datasets[2] = (trainingSet2,devSet2,testSet2,SVC_para_2,NB_para_2)
    datasets[3] = (trainingSet3,devSet3,testSet3,SVC_para_3,NB_para_3)
    datasets[4] = (trainingSet4,devSet4,testSet4,SVC_para_4,NB_para_4)
    datasets[5] = (trainingSet5,devSet5,testSet5,SVC_para_5,NB_para_5)

    return datasets[run]

def assignData(index,texts,attributes,signaturesMasterList):

    X_txt = []
    X_att = []
    Y = []
    for choice in index:
        X_txt.append(texts[choice])
        X_att.append(attributes[choice])
        Y.append(signaturesMasterList[choice][1])
    X_att = np.array(X_att)

    return X_txt,X_att,Y


if __name__ == "__main__":
    main()
