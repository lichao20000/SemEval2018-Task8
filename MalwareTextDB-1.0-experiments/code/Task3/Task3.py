"""
------------------------------------------------------------
Task3.py
------------------------------------------------------------

Predict relation labels and generates .predicted_relations
files that contain the predictions of the rule-based model,
treating Task 3 as a binary classification problem.

Overall scores are generated in ./ folder as 
./overall_results and ./overall_scores.
------------------------------------------------------------
"""

from os import listdir
from subprocess import call


def main():

  # Generate .rel files

  numberTokenPhrases("../../data/tokenized/","./data/")

  sourceFolder = "./data/"

  for row in listdir(sourceFolder):
    if row[-3:]=="rel":
      sentences = []
      sentence = []
      with open(sourceFolder+row,'r') as f:
        for line in f:
          if line!='\n': sentence.append(line[:-1].split(' '))
          else:
            if len(sentence)>0: sentences.append(sentence)
            sentence = []
        if len(sentence)>0: sentences.append(sentence)

      # Get label sequence
      for sentenceNo,sentence in enumerate(sentences):
        sequence = []
        i = -1
        for token in sentence:
          lastWord = ''
          if token[-1]!='O':
            if i>-1:
              sequence[i]["tokenLen"] = phraselength
              sequence[i]["lastWord"] = lastWord
            i+=1
            sequence.append({"firstWord":token[0],"tokenNo":token[-1],"tokenType":token[-2],"POS":token[-3],"prediction":'0:ROOT'})
            phraselength = 1
          elif token[-2][0]=='I':
            phraselength+=1
            lastWord = token[0]
        if len(sequence)>0:
          sequence[-1]["tokenLen"] = phraselength
          sequence[-1]["lastWord"] = lastWord

        # Predict using rules
        prevEntity = 'X'
        prevVerb = 'X'
        prevPrep = 'X'

        for tokenNo,token in enumerate(sequence):

          if token["tokenType"]=='B-Entity':
            if prevPrep==tokenNo-1:
              sequence[tokenNo]["prediction"] = sequence[prevPrep]["tokenNo"]+':ModObj'
            elif prevVerb==tokenNo-1:
              sequence[tokenNo]["prediction"] = sequence[prevVerb]["tokenNo"]+':ActionObj'
            else: prevEntity = tokenNo

          if token["tokenType"]=='B-Action':
            if token["tokenLen"]==1 and prevEntity!='X':
              sequence[tokenNo]["prediction"] = sequence[prevEntity]["tokenNo"]+':SubjAction'
            elif token["firstWord"]=='be' and prevEntity!='X':
              sequence[prevEntity]["prediction"] = token["tokenNo"]+':ActionObj'
            elif (token["firstWord"]=='is' or token["firstWord"]=='are' or token["firstWord"]=='was' or token["firstWord"]=='were') and token["lastWord"][-3:]!='ing' and prevEntity!='X':
              sequence[prevEntity]["prediction"] = token["tokenNo"]+':ActionObj'
            prevVerb = tokenNo

          elif token["tokenType"]=='B-Modifier':
            if prevVerb!='X':
              sequence[tokenNo]["prediction"] = sequence[prevVerb]["tokenNo"]+':ActionMod'
            prevPrep = tokenNo

        for token in sequence:
          for token2No,token2 in enumerate(sentence):
            if token2[-1]==token["tokenNo"]:
              sentences[sentenceNo][token2No].append(token["prediction"])

      # Write predictions to file
      remove = []
      for sentenceNo,sentence in enumerate(sentences):
        important = False
        for token in sentence:
          if token[3]!='O' and token[4]=='O': print token
          if token[3]!='O': important = True
        if important==False:
          remove.append(sentenceNo)
      for i in reversed(remove):
        sentences.pop(i)

      # Load format from rel-bin
      resultsFormat = []
      group = []
      with open(sourceFolder+row[:-3]+'rel-bin','r') as f:
        for line in f:
          if line!='\n': group.append(line[:-1].split('\t'))
          else:
            if len(group)>0: resultsFormat.append(group)
            group = []

      for groupNo,group in enumerate(resultsFormat):
        for lineNo,line in enumerate(group):
          for token in sentences[groupNo]:
            if len(token)>4 and int(line[0])==int(token[4].split(':')[0]) and int(line[1])==int(token[3]):
              resultsFormat[groupNo][lineNo].append(token[4].split(':')[1])

      for groupNo,group in enumerate(resultsFormat):
        for lineNo,line in enumerate(group):
          if len(line)<4: resultsFormat[groupNo][lineNo].append('O')

      with open(sourceFolder+row[:-3]+'predicted_relations','w') as f:
        for group in resultsFormat:
          for line in group:
            string = ''
            for entry in line:
              string+=entry+'\t'
            string = string[:-1]+'\n'
            f.write(string)
          f.write('\n')

  # Compile results in a single file
  text = ""
  for row in listdir(sourceFolder):
    if "predicted_relations" in row:
      with open(sourceFolder+row,'r') as f:
        for line in f: text+=line

  with open("./overall_results",'w') as f:
    f.write(text)

  # Score overall results
  results_file = "overall_results"
  scores_file = "overall_scores"
  command = "perl conlleval -r < \""+results_file+"\" >> \""+scores_file+"\""
  call(command, shell=True)


def numberTokenPhrases(sourceFolder,targetFolder):

  for row in listdir(sourceFolder):
    lines = ''
    i = 1
    if "tokens" in row:
      with open(sourceFolder+row,'r') as f:
        for line in f:
          if len(line.split(' '))>1 and line.split(' ')[2][0]=='B':
            string = line[:-1]+' '+str(i)+'\n'
            i+=1
          elif len(line.split(' '))>1:
            string = line[:-1]+' O\n'
          else:
            string = line
            i = 1
          lines+=string
      with open(targetFolder+row[:-6]+'rel','w') as f:
        f.write(lines)

  return


if __name__ == "__main__":
  main()
